# ğŸ“˜ Gensim ê¸°ë°˜ LDA ëª¨ë¸ë§
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df_raw = pd.read_parquet("df_raw_with_keywords.parquet")

from gensim.corpora import Dictionary
from gensim.models.ldamodel import LdaModel


# í‚¤ì›Œë“œë¥¼ í† í° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
df_raw["keywords"] = df_raw["keywords"].str.split()


from collections import Counter

# ìƒìœ„ 200ê°œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ ì¶œë ¥ (ìˆ˜ë™ ë¶ˆìš©ì–´ í•„í„°ë§ ì°¸ê³ ìš©)
all_tokens = [token for tokens in df_raw["keywords"] for token in tokens]
token_counts = Counter(all_tokens)
top_200_tokens = token_counts.most_common(200)

print("\nğŸ“Œ ìƒìœ„ 200ê°œ ìì£¼ ë“±ì¥ ë‹¨ì–´:")
for word, count in top_200_tokens:
    print(f"{word}: {count}")

# ìƒìœ„ ê³ ë¹ˆë„ ë‹¨ì–´ ì €ì¥ (ìˆ˜ë™ í¸ì§‘ í›„ ë¶ˆìš©ì–´ ì ìš©)
with open("top200_frequent_words.txt", "w") as f:
    for word, count in top_200_tokens:
        f.write(f"{word}\n")

print("ğŸ“ top200_frequent_words.txt ì €ì¥ ì™„ë£Œ (ë¶ˆìš©ì–´ë¡œ ì“¸ ë‹¨ì–´ ìˆ˜ë™ í¸ì§‘ í›„ custom_stopwords.txtë¡œ ì €ì¥í•˜ì„¸ìš”)")

# custom_stopwords.txtê°€ ì´ë¯¸ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°ì—ë§Œ ìƒì„±
import os
if not os.path.exists("custom_stopwords.txt"):
    with open("custom_stopwords.txt", "w") as f:
        for word, _ in top_200_tokens:
            f.write(f"{word}\n")
    print("ğŸ“ custom_stopwords.txt ì´ˆê¸° ìƒì„± ì™„ë£Œ (ë¶ˆìš©ì–´ ìˆ˜ì • ê°€ëŠ¥)")
else:
    print("ğŸ“ custom_stopwords.txtê°€ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ì‚¬ìš©ì ì§€ì • ë¶ˆìš©ì–´ ìë™ ì ìš©
try:
    with open("custom_stopwords.txt", "r") as f:
        custom_stopwords = set(line.strip() for line in f if line.strip())
    df_raw["keywords"] = df_raw["keywords"].apply(lambda tokens: [t for t in tokens if t not in custom_stopwords])
    print(f"ğŸ§¹ ì‚¬ìš©ì ì •ì˜ ë¶ˆìš©ì–´ {len(custom_stopwords)}ê°œ ì ìš© ì™„ë£Œ")
except FileNotFoundError:
    print("âš ï¸ custom_stopwords.txt íŒŒì¼ì´ ì—†ì–´ ë¶ˆìš©ì–´ ì œê±°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

# Dictionary ë° Corpus ìƒì„±
dictionary = Dictionary(df_raw["keywords"].tolist())
# ë¬¸ì„œ ìˆ˜ ê¸°ì¤€ ë‹¨ì–´ í•„í„°ë§: ë„ˆë¬´ ë“œë¬¼ê±°ë‚˜ í”í•œ ë‹¨ì–´ ì œê±°
dictionary.filter_extremes(no_below=10, no_above=0.7)
corpus = [dictionary.doc2bow(tokens) for tokens in df_raw["keywords"]]

#
# ğŸ” ìµœì ì˜ kê°’(í† í”½ ìˆ˜)ì„ ì°¾ìœ¼ë ¤ë©´ coherence score ë˜ëŠ” perplexity ê¸°ë°˜ ë°˜ë³µ ì‹¤í—˜ì´ í•„ìš”í•¨
# ì˜ˆ: ì—¬ëŸ¬ kê°’ì— ëŒ€í•´ coherence scoreë¥¼ ë¹„êµí•˜ê³  ê°€ì¥ ë†’ì€ k ì„ íƒ

lda_gensim = LdaModel(
    corpus=corpus,
    id2word=dictionary,
    num_topics=5,
    random_state=42,
    passes=20,
    iterations=400,
    alpha='auto',  # ë¬¸ì„œë³„ í† í”½ ë¶„í¬ ë™ì  ìµœì í™”
    eta=0.05       # í† í”½ë³„ ë‹¨ì–´ ì§‘ì¤‘ë„ ì¡°ì ˆ
)

# í† í”½ë³„ ì£¼ìš” ë‹¨ì–´ ì¶œë ¥
print("\nğŸ“Œ Gensim LDA ì£¼ìš” í† í”½:")
for i, topic in lda_gensim.print_topics(num_words=10):
    print(f"Topic {i}: {topic}")

# ê° í† í”½ë³„ ëŒ€í‘œ ë¬¸ì„œ 3ê°œì”© ì¶œë ¥
print("\nğŸ“Œ í† í”½ë³„ ëŒ€í‘œ ë¬¸ì„œ:")
import numpy as np

topic_dist = [lda_gensim.get_document_topics(doc, minimum_probability=0.0) for doc in corpus]
topic_vectors = []
for dist in topic_dist:
    vec = [0.0] * lda_gensim.num_topics
    for topic_id, prob in dist:
        vec[topic_id] = prob
    topic_vectors.append(vec)

topic_doc_map = {i: [] for i in range(lda_gensim.num_topics)}
for doc_idx, doc in enumerate(topic_vectors):
    dominant_topic = np.argmax(doc)
    topic_doc_map[dominant_topic].append((doc_idx, doc[dominant_topic]))


# ğŸ“ í† í”½ë³„ ëŒ€í‘œ ë¬¸ì„œ ì €ì¥
with open("topic_representative_docs.txt", "w", encoding="utf-8") as f:
    for topic_id, doc_scores in topic_doc_map.items():
        f.write(f"\nğŸ”· Topic {topic_id} ëŒ€í‘œ ë¬¸ì„œ:\n")
        for doc_idx, score in sorted(doc_scores, key=lambda x: -x[1])[:3]:
            f.write(f"- ë¬¸ì„œ {doc_idx} (score: {score:.4f})\n")
            f.write(f"  â†’ í† í°: {' '.join(df_raw.iloc[doc_idx]['keywords'])}\n")
print("ğŸ“ í† í”½ë³„ ëŒ€í‘œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: topic_representative_docs.txt")


# ğŸ“Š pyLDAvis ê¸°ë°˜ LDA ì‹œê°í™” ë° HTML ì €ì¥
if __name__ == "__main__":
    import pyLDAvis.gensim_models
    import pyLDAvis

    print("ğŸ“Š pyLDAvis ì‹œê°í™” HTML ìƒì„± ì¤‘...")
    vis = pyLDAvis.gensim_models.prepare(lda_gensim, corpus, dictionary)
    pyLDAvis.save_html(vis, 'lda_gensim_vis.html')
    print("âœ… ì‹œê°í™” ì €ì¥ ì™„ë£Œ: lda_gensim_vis.html (ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ë³´ì„¸ìš”)")


# ğŸ“ Gensim LDA ë²¡í„° ì €ì¥

df_vectors = pd.DataFrame(topic_vectors, columns=[f"topic_{i}" for i in range(lda_gensim.num_topics)])
df_vectors["isbn"] = df_raw["isbn"].values
df_vectors.to_parquet("book_gensim_lda_vectors.parquet", index=False)
print("âœ… Gensim LDA ë²¡í„° ì €ì¥ ì™„ë£Œ: book_gensim_lda_vectors.parquet")
